{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Klassifizierung</h2>\n",
    "<h4>Hier nur die endgültige Klassifizierung, auskommentiert die Trainings-Klassifizierung</h4>\n",
    "<h5>Vorgehen:  </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1498\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "dataClaNEG = pd.read_csv(\"C:\\\\Users\\\\ojkbe\\\\OneDrive\\\\Documents\\\\7. Semester\\\\KI\\\\Übung\\\\preprocessedDataNEG.csv\", sep=',', usecols = ['Text', 'Label'], engine='python')\n",
    "dataClaPOS = pd.read_csv(\"C:\\\\Users\\\\ojkbe\\\\OneDrive\\\\Documents\\\\7. Semester\\\\KI\\\\Übung\\\\preprocessedDataPos.csv\", sep=',', usecols = ['Text', 'Label'], engine='python')\n",
    "dataClaTEST = pd.read_csv(\"C:\\\\Users\\\\ojkbe\\\\OneDrive\\\\Documents\\\\7. Semester\\\\KI\\\\Übung\\\\preprocessedDataTest.csv\", sep=',', usecols = ['Text', 'Label'], engine='python')\n",
    "\n",
    "tupelNeg = dataClaNEG.shape\n",
    "lengthNeg = tupelNeg[0]\n",
    "tupelPos = dataClaPOS.shape #kürzer als 1500 weil zwei Einträge im Orginalen fehlen!\n",
    "lengthPos = tupelPos[0]\n",
    "\n",
    "lengthTrain = lengthNeg + lengthPos\n",
    "\n",
    "print(lengthNeg)\n",
    "print(lengthPos)\n",
    "print((dataClaTEST.shape)[0]) #1500 1498 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all data:  (3998, 2)\n"
     ]
    }
   ],
   "source": [
    "dataCla = pd.concat([dataClaPOS, dataClaNEG, dataClaTEST], axis=0, join='outer', join_axes=None, ignore_index=True,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "print('Shape all data: ', dataCla.shape) #müsste 3998, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TFIDF</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "dataVEC = pd.DataFrame((vectorizer.fit_transform(dataCla['Text']).toarray()), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Labels wieder einfügen</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClaLabel = pd.concat([dataVEC, dataCla], axis=1, join='outer', join_axes=[dataVEC.index], ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True, sort=False)\n",
    "\n",
    "dataClaLabel.drop(['Text'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Garbage Collector</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataVEC, dataCla, dataClaNEG, dataClaPOS, dataClaTEST = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "lst = [dataVEC, dataCla, dataClaNEG, dataClaPOS, dataClaTEST]\n",
    "del dataVEC, dataCla, dataClaNEG, dataClaPOS, dataClaTEST\n",
    "del lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataClaLabel.values\n",
    "\n",
    "tupelMes = dataClaLabel.shape\n",
    "\n",
    "lengthLabel = tupelMes[0]\n",
    "widthLabel = tupelMes[1]\n",
    "\n",
    "train_x = array[0:lengthTrain,0:(widthLabel-1)]\n",
    "train_y = array[0:lengthTrain,widthLabel-1]\n",
    "test_i = array[lengthTrain:lengthLabel, 0:(widthLabel-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Im folgenden wird getestet welches Modell am besten ist für gegebene Trainingsdaten.\n",
    "Auskommentiert</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_size = 0.20\n",
    "#seed = 42\n",
    "#train_x, valid_x, train_y, valid_y = model_selection.train_test_split(x, y, test_size=validation_size, random_state=seed)\n",
    "seed = 42 #7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "#models.append(('LR', LogisticRegression()))\n",
    "#models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "#models.append(('KNN', KNeighborsClassifier()))\n",
    "#models.append(('CART', DecisionTreeClassifier()))\n",
    "#models.append(('NB', GaussianNB()))\n",
    "#models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, train_x, train_y, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ergebnisse:</h4>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "      LogisticRegression\n",
    "    </td>\n",
    "    <td>\n",
    "      0,85\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      KNeighborsClassifier\n",
    "    </td>\n",
    "    <td>\n",
    "      0,75\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      DecisionTreeClassifier\n",
    "    </td>\n",
    "    <td>\n",
    "      0,69\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      GaussianNB\n",
    "    </td>\n",
    "    <td>\n",
    "      0,61\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      SVM\n",
    "    </td>\n",
    "    <td>\n",
    "      0,51\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predictions mit LogisticRegression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ojkbe\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1\n",
      " 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0\n",
      " 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1\n",
      " 1 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0\n",
      " 1 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0\n",
      " 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0\n",
      " 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1\n",
      " 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1\n",
      " 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0\n",
      " 1 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1\n",
      " 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 0\n",
      " 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0\n",
      " 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 0 1 1 0 1\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1\n",
      " 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 1 1\n",
      " 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 0\n",
      " 0 1 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 0 0 0\n",
      " 1 0 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 1\n",
      " 0]\n",
      "1\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(train_x, train_y)\n",
    "predictions = LR.predict(test_i)\n",
    "predictions = predictions.astype(int)\n",
    "print(predictions)\n",
    "print(predictions[0])\n",
    "print(len(predictions))\n",
    "import numpy\n",
    "numpy.savetxt('Predictions.csv', predictions.astype(int), fmt='%i', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
